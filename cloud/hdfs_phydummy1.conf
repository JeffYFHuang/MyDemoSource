# Name the components on this agent
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# Source definitions
a1.sources.r1.type = org.apache.flume.source.http.HTTPSource
a1.sources.r1.type = http
a1.sources.r1.bind = 10.10.10.21
a1.sources.r1.port = 44448
a1.sources.r1.handler = org.apache.flume.sink.solr.morphline.BlobHandler
# a1.sources.r1.handler = org.apache.flume.source.http.JSONHandler

# Interceptor definitions
#a1.sources.r1.interceptors = i1
#a1.sources.r1.interceptors.i1.type = regex_extractor
#a1.sources.r1.interceptors.i1.regex = (\elm[0-9]+)
#a1.sources.r1.interceptors.i1.serializers = s1
#a1.sources.r1.interceptors.i1.serializers.s1.type = org.apache.flume.interceptor.RegexExtractorInterceptorPassThroughSerializer
#a1.sources.r1.interceptors.i1.serializers.s1.name = schoolId

# Custom interceptor defined to determine hour range
a1.sources.r1.interceptors = i2
a1.sources.r1.interceptors.i2.type = com.liteon.icgcloud.HourInterceptor$Builder
a1.sources.r1.interceptors.i2.mHourRange = mHourRange
a1.sources.r1.interceptors.i2.mSchoolId = mSchoolId
# following code related to year, month and date are added for experimentation and testing
a1.sources.r1.interceptors.i2.mYear = mYear
a1.sources.r1.interceptors.i2.mMonth = mMonth
a1.sources.r1.interceptors.i2.mDate = mDate

# Channel definitions
a1.channels.c1.capacity = 50000
a1.channels.c1.transactionCapacity = 50000
a1.channels.c1.type = memory

# Sink definitions
#a1.sinks.k1.hdfs.path = hdfs://hadoop-cluster-master-0:9000/data/physical/in/%{schoolId}/%Y/%m/%d/%{hourRange}
# following code is added for experimentation and testing purpose
a1.sinks.k1.hdfs.path = hdfs://hadoop-cluster-master-0:9000/data/physical/in/%{mSchoolId}/%{mYear}/%{mMonth}/%{mDate}/%{mHourRange}
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.batchSize = 2000
a1.sinks.k1.hdfs.rollSize = 2000000000
a1.sinks.k1.hdfs.rollInterval = 1800
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.minBlockReplicas = 1
a1.sinks.k1.hdfs.callTimeout = 120000
#a1.sinks.k1.hdfs.inUsePrefix=. 
a1.sinks.k1.hdfs.useLocalTimeStamp = true


# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1


