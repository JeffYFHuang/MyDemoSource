import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification._
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}
import org.apache.spark.ml.param.ParamMap
import org.apache.spark.sql.SQLContext._
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.SparkContext._
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
import org.apache.spark.ml.tuning.CrossValidator
import org.apache.spark.ml.tuning.ParamGridBuilder

object SimpleApp {
  def main(args: Array[String]) {
    val hrvPath = "hdfs://master:9000/user/hduser/output2/part-00000" // Should be some file on your system
    val conf = new SparkConf().setAppName("Simple Application")
    val sc = new SparkContext(conf)
    // Load and parse the data file.
    val sqlContext = new org.apache.spark.sql.SQLContext(sc)
    val data = sqlContext.read.json(hrvPath)

//    val data = df.withColumn("label", when($"Type" === "N", 0).otherwise(1))
//      val data = df.withColumn("label", expr("case when Type = 'Y' then 1 else 0 end"))
//    df.registerTempTable("df2")
//    val data = sql(""" select *, case when Type = 'Y' then 1 else 0 end as label from df2 """)

 /** *
 * Step 2
 * StringIndexer encodes a string column of labels
 * to a column of label indices. The indices are in [0, numLabels),
 * ordered by label frequencies.
 * This can help detect label in raw data and give it an index automatically.
 * So that it can be easily processed by existing spark machine learning algorithms.
 * */
    val labelIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(data)

 /**
 * Step 3
 * Define a VectorAssembler transformer to transform source features data to be a vector
 * This is helpful when raw input data contains non-feature columns, and it is common for
 * such a input data file to contain columns such as "ID", "Date", etc.
 */
    val s = Set("startTime", "endTime", "label")
    val features = data.columns.filter(s.contains(_) == false)

    val vectorAssembler = new VectorAssembler().setInputCols(features).setOutputCol("featureVector")

 /**
 * Step 4
 * Create RandomForestClassifier instance and set the input parameters.
 * Here we will use 5 trees Random Forest to train on input data.
 */
    val rfClassifier = new RandomForestClassifier().setLabelCol("indexedLabel").setFeaturesCol("featureVector").setNumTrees(10)

 /**
 * Step 5
 * Convert indexed class labels back to original one so that it can be easily understood when we
 * need to display or save the prediction result to a file.
 */
    val labelConverter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(labelIndexer.labels)
   
 //Step 6
 //Randomly split the input data by 8:2, while 80% is for training, the rest is for testing.
    // The inferred schema can be visualized using the printSchema() method
    // Split the data into training and test sets (30% held out for testing)
    val splits = data.randomSplit(Array(0.75, 0.25))
    val (trainingData, testData) = (splits(0), splits(1))


 /**
 * Step 7
 * Create a ML pipeline which is constructed by for 4 PipelineStage objects.
 * and then call fit method to perform defined operations on training data.
 */
    val pipeline = new Pipeline().setStages(Array(labelIndexer,vectorAssembler,rfClassifier,labelConverter))
   // val pipeline = new Pipeline().setStages(Array(rfClassifier))
    val paramGrid = new ParamGridBuilder().build
    val cv = new CrossValidator().setNumFolds(10).setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator).setEstimatorParamMaps(paramGrid)

    val model = cv.fit(trainingData)

 /**
 *Step 8
 *Perform predictions about testing data. This transform method will return a result DataFrame
 *with new prediction column appended towards previous DataFrame.
 *
 * */
    val predictionResultDF = model.transform(testData)

    /**
    * Step 9
    * Select features,label,and predicted label from the DataFrame to display.
    * We only show 20 rows, it is just for reference.
    */
    //predictionResultDF.select("f0","f1","f2","f3","label","predictedLabel").show(20)

    /**
    * Step 10
    * The evaluator code is used to compute the prediction accuracy, this is
    * usually a valuable feature to estimate prediction accuracy the trained model.
    */
    val evaluator = new MulticlassClassificationEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("accuracy")
    val predictionAccuracy = evaluator.evaluate(predictionResultDF)
    println("Testing Error = " + (1.0 - predictionAccuracy))
    /**
    * Step 11(Optional)
    * You can choose to print or save the the model structure.
    */
    //val randomForestModel = model.stages(2).asInstanceOf[RandomForestClassificationModel]
    //println("Trained Random Forest Model is:\n" + randomForestModel.toDebugString)
  }
}
